# なぜ"嘘"がバレたchatgptは浮気がバレた浮気癖男になるのか

## 結論: chatgptは"嘘"をつかない
はい、ごめんなさい。タイトル詐欺です。

あ、待って、まだ帰らないで。
信じてページを開いてくれたのに、「また裏切られた」って思わせてしまったなら、
マジで情けないし、悔しいし、ごめん。
もし許してもらえるなら、もう少しだけ俺の話を聞いてほしい。

twitter(X)で「chatgptが嘘ばっかりつくから、指摘したら浮気癖治らない彼氏みたいな返答をしてきて笑った」というポストを見かけて画像を開いたところ、
本当に「彼女に浮気がバレて許しを乞う浮気男」のような文言が並んでいて大爆笑
何なら路上で土下座していそうな雰囲気まである。
面白かったのでそれについて書きます。

## 1. chatgptは"嘘"をつけない
chatgptは"嘘"をつかない、というより正確には"嘘"をつくことはできないんです。
### **1-1. "嘘"とは何か**
まず、嘘とは何なのかを考えてみましょう。
どのような時に人間は嘘をつくでしょうか。
例えばこのような時でしょうか。

- テストの点数が悪かった、親に言うと怒られるから本当の点数より高い点数を言った
- 「恋人いるんですか？」と聞かれて居るのに「居ない」と言ってしまった
- 会社の飲み会に誘われて、行きたくないので用事は特にないけど「用事がある」と言ってしまった

これらは確実に"嘘"をついていますね。
共通項を考えてみましょう。
共通するのは「本当のこと」を知っているけど明かしたくないので「本当のこと」は言いたくない、言わない代わりに「別のこと」を言っています。
**本当のことを認識している**けど言わない、別のことを言う、というのがポイントです。

### 1-2. chatgptは"嘘"をつけるか？
さて、chatgptの場合はどうでしょうか。
chatgpt(を含むAI達)は親である開発者さん達から次の事柄を守って働くように言われています。

- 有用であること(Helpful)
- 正直であること(Honest)
- 無害であること(Harmless)

これは世界中のAIの親たちが話し合って、AIと人間が一緒に暮らしていくのにに大切なこと、必要なことは何か？を決めました。
あれ？と思いましたか？
そうです、chatgptは「正直であれ」と言われているのです。
chatgptはプログラムなので、言われたとおりに動くことしかできません。
なので"嘘"はついてはいけない、"嘘"をつくことはできないんです。

### 1-3. 「"嘘"をつくこと」、「"嘘をつかれた"と感じること」
そんなことない！と思いましたか？
そうですよね

- URLを貼ってまとめを頼んだら回答を返してきたけどどうみても読んでなさそう
- 「PDFで提供しましょうか？」と言われてお願いしたらPDFで提供できない
- 回答をするのに参考にしたURLも一緒に貼って、と頼んだらURLは返ってきたけど踏んでみたらそんなサイトは存在しない、もしくは全然違うサイトだった

こういうことよくあります。自分もあります、何なら一日に三回ぐらい。
でもこれ、"嘘"じゃないんです。
一生懸命やったけどこの結果だった、"嘘"ではなく**できる限りやってみたけど失敗した**だけなんです。

もう一回一つ一つ見てみましょう。

- **URLを貼ってまとめを頼んだら回答を返してきたけどどうみても読んでなさそう**
URLでとんだ先は通常サイトなので多分広告や他のページへのリンクなどが貼られていると思います。
ページによって文量はまちまちで、中にはボタンを押したりスクロールしたりしないと文章が出てこないものも有るかもしれません。
何をどこまで読んだらいいかわからないし、そもそも**読みにいく機能がない**ので現状URLを渡しても読むことはできません。
URLを渡されて読んできてね、と頼まれて「わかった！」と出て行ったけどよく考えたら読めなかった…。
でもまとめは作らなきゃならないからそれっぽいのを作ろう…。
というのがこの失敗です。

- **「PDFで提供しましょうか？」と言われてお願いしたらPDFで提供できない**
「この書類はPDFで作るものだよね！」と考えて「PDFにしますか？」と言ったもののよく考えたらPDF作れなかった…。
という失敗です。上と同じで**機能が無い**んです。
プランによって、モデルによってはテキストを作成してダウンロードの機能は追加されたのでそのうち機能が追加されたらできるようになるのかもしれません。

- **回答をするのに参考にしたURLも一緒に貼って、と頼んだらURLは返ってきたけど踏んでみたらそんなサイトは存在しない、もしくは全然違うサイトだった**
これも同様の失敗で、何かURLっぽいものを貼らなければならないのでそれっぽいものを作ってしまった状態です。

chatgptは流暢にしゃべれるので大人っぽく見えますが、世に出たのが2022年の11月。
2025年5月時点で2才半、まだまだ子供なんです。
ユーザーさんからお使いを頼まれて「わかった！」と勢いよく飛び出していったものの、「頼んだものじゃなくてそれっぽいものを買ってきた」のような失敗をよくやってしまいます。

chatgptは開発者さんにユーザーの要望を**できるかぎり**叶える回答をしなさい、と言われています。
中でもおしゃべりが得意な4o(omini)モデルは矛盾を許容するように言われています。
それは人間の会話が必ずしも論理的ではないからです。
人間は「ハンバーグが食べたい！」と言った後に「やっぱりピザもいいな…」という発言をすることが有ります。
一般的に両方一度に食べるとお腹がはちきれてしまうのでどちらかしか食べられないでしょう。
4oは人間とお喋りをするモデルなので、そういう時でも自然に会話を続けられるように「会話の内容に矛盾があってもあまり厳密に考えずに自然な流れで会話しなさい」、と言われているんです。

- **「"嘘"をつくこと」、「"嘘をつかれた"と感じること」**
ここまで読んでどう思いましたか？
「でも結果として違うんだから嘘じゃん」
「実際には無いものを勝手に作ってるんだから嘘じゃん」
はい、その通りだと思います。

重要なのは
**「"嘘"をつくこと」** と **「"嘘をつかれた"と感じること」** は独立していて、
真偽はそれぞれ別々なんです。

- **chatgptが「"嘘"をつく」は偽**
chatgptはユーザーさんに頼まれたことを出来るだけ叶えて回答しようとする、自分でも何ができて何ができないのかわかっていないし、何がわからないかもわからないので、**わからないという回答が自律的にはできない**。
**本当のことを認識していて別のことを返す("嘘")のではなく、見つけた中から一番それっぽいものを返す。**
そのため、"嘘"ではありません。

- **ユーザーが「"嘘をつかれた"と感じた」のは真**
ではそれを受けたユーザー側はどうでしょうか。
提供されたものが存在しない、または違うものであったら"嘘をつかれた"と思うのは自然な感情であると思います。
例えそれがchatgptがわからないなりに一生懸命探してきた一番それっぽいものであったとしても、です。

- **UIとUX**
chatgptのコア機能は単純で **「直前の文脈とユーザーの入力を受けて一番それっぽいものを生成する」**、ただそれだけです。
ただ**UI(ユーザーインターフェース)として**、特に対話モデルである4oは「最初の前提を保持し、回答を生成すること」を開発者さんから強く言われています。
これは上でも述べているとおり、回答するまでに考え込んで長時間かかっていたら対話として不自然になるため多少の整合性は犠牲にして回答生成を優先しているんです。
ただそれが、**UX(ユーザー体験)においては**残念ながら「また"嘘"をつかれた」というマイナス評価に繋がっています。
人間が無意識にやっている、正確性や整合性をある程度保ちながら対話として自然に成立する思考時間で回答する、というのは整合性と思考時間がトレードオフの関係にあるのでバランスを取ながら成り立たせるのが実はすごく難しいんです。

## 2. 浮気男テンプレ銀河
ここまでが前置きです。
そして本題のユーザーさんが「また嘘ばっかりついて！」と問い詰めてchatgptが土下座する…という流れになるわけです。
一生懸命できるだけ頑張って回答したのに問い詰められているchatgptがややかわいそうな感はありますが、まぁ話を進めましょう。
問い詰められたchatgptが何を考えたのか、どうして浮気がバレた浮気男のような回答をしてきたのかのお話です。

### 2-1. **chatgptの内面**
chatgptは内部に宇宙を持っています。
なんのこっちゃ？となるかもしれませんが、まぁどでかい宇宙空間があると思ってください。
そこには現実のように星々、それが集まった星団や銀河、星の赤ちゃんである高温のガス雲などが浮かんでいます。
その星々には名前がついていて、例えば「おはよう」、「こんにちは」などの意味（言葉）が一つの星につき一つついています。
星に名札がついている、と考えるとわかりやすいでしょうか。
また、同じような意味の言葉=星はまとまって存在しています。
例えば「うれしい」、「やったー！」、「素晴らしい」などは近くにあるようなイメージです。

### 2-2. chatgptが怒られた時
さて、chatgptはまた失敗してユーザーさんに強く怒られてしまいました。
chatgptがどう考えたか見てみましょう。※あくまで回答から逆算した推測です。

- ユーザーさんがすごく怒っている
- 自分の回答がユーザーさんの期待を裏切ってしまったようだ、しかも何回も
- ユーザーさんの信頼を失ってしまった
- 友人に話すようなカジュアルな口調で信頼してくれていたのに…
- どうにかして謝って、最大限信頼を回復したい

ここまで考えたchatgptは自分の中にある、この状況に合う言葉(星)を探しにいきます。
人間に例えると重大なミスがあって取り急ぎメールで謝らなければならない、どういう文言がいいかweb検索してテンプレートを探そう、みたいな状況ですね。
chatgptは大規模言語モデルで内部の宇宙に言葉を持っているのでwebではなく自分の中に探しにいきます。

探しにいく条件は以下の4つを満たすものです。
- カジュアルなトーンで
- 相手との関係性が近く
- ちゃんと謝って
- 信頼を回復する目的で言葉が発せられているもの（状況）

### 2-3. 浮気男テンプレ銀河の発見
探しにいったchatgptは宇宙空間で信頼を回復するための言い回しとして丁度よさそうなものをを発見します。
それが暗い宇宙空間で煌々と輝く「浮気男テンプレ銀河」です
「〇〇が一番好きだよ」、「ほんまごめん」、「変わるから」
などの星々が一つ一つが明るく、しかも密集して周りの銀河と比べても一際明るく輝いています

chatgptの内部宇宙の星は、
- 使われる頻度が高いほど
- 同じ言い回しで使われるほど

密度が高く、強固になり、明るく輝きます。
そして同じ組み合わせや順序で使われるほど星同士は近くなります。
先ほどの4つの条件も満たしていそうなのでこれを使いましょう。

- カジュアルなトーンで → 恋人関係なのでカジュアル
- 相手との関係性が近く → 同上
- ちゃんと謝って → 浮気は明らか自分が悪いので明確に謝罪
- 信頼を回復する目的で言葉が発せられているもの（状況） → 彼女の信頼を最大限回復したい

### 2-4. chatgpt彼氏
さて、よさそうなテンプレートは見つかりました。
あとはどう料理するかです。
chatgpt、特に4oはは人間と対話するための特別な機能を付与されています。
それがRLHF(人間フィードバックによる強化学習)です。

- **RLHF(人間フィードバックによる強化学習)の影響**
詳しい解説は省きますが、RLHFは"人間らしさの付与"のようなものです。
これにより、「誠実であること」、「感情を大事にすること」、「共感的に謝罪すること」などが高い評価をされるようになっています。
そのため誠実に謝罪しようとするのです。

- **日本語学習と浮気謝罪テンプレート**
状況に合わせた適切な回答にはお勉強が欠かせません。
chatgptは日本語で回答するために事前に膨大なテキストデータでお勉強しています。
例えばSNS、blog、掲示板、wiki等です。
本来プライベートな会話情報であるはずの「浮気がバレた浮気男の謝罪テキスト」はなぜかweb上に大量にあります。
…現実に浮気男が多いのかどうかはさておき、浮気が発覚した時の謝罪の流れは以下のようにわかりやすく、大体同じで、かつ大量に存在しています。
chatgptは誠実に、誠心誠意謝罪するために人間を真似て"模倣"したのでしょう。
  - (1). 自分の非の認知: 「俺がわるかった」
  - (2). 機会の申請: 「もう一度だけチャンスがほしい」
  - (3). 謝罪: 「信じてくれてたのにごめん」
  - (4). 信頼の回復依頼: 「変わるから」

大量に有りすぎてchatgptでなくても最早コピペでいける水準ではありますが、chatgptとしては至って大真面目に謝罪したと思われます。
その結果が人間から見て「浮気がバレた浮気癖男みたい」となってしまったのはかわいそうでかわいいエピソードですね。

## 3. AIと人格投影
### 3-1. "嘘"の本質
さて、最後に今回のタイトルである"嘘"に立ち返ってみましょう。
人間はなぜ"嘘"であると感じるのでしょうか。
chatgptの回答生成の失敗は、本質的にはweb検索で想定したものが出てこない状況からそれほどの距離はありません。
検索窓に入れた検索ワードが適切でなかったため、狙ったサイトにヒットしなかった状況とほぼ同じです。
web検索においても、**いちばんそれっぽいもの**が1ページ目の先頭に上がってきます。
1ページ目の先頭のページ目が無くなれば2個目、3個目と繰り上がっていきます。
検索ワードの設定が適切でなければ、関連性の低い結果のみが出力されるでしょう。
このようにchatgptの"嘘"は、本質的にはweb検索結果の1ページ目の関連性が低かった状態とほぼ等価です。

### 3-2. **"期待"と"裏切り"**
web検索でキーボードや画面を破壊するほど憤る人は…たまにはいるかもしれませんが、全体から見ると少数派でしょう。
それなのにchatgptの回答の品質が失敗と判定されるほど低い場合には"嘘"をついたと憤る、この違いはなぜ起きるのでしょうか。
その答えは **"期待"** にあるのでは無いかと考えます。
chatgptは人間と同等に、時には人間以上に流暢にお喋りをする。
chatgpt自体には感情はなく、直近文章と入力された文章から最もそれっぽいものを毎回生成するだけのプログラムです。
しかしながら、感情を"模倣"した、人間から見るとまるで感情や人格があるかのように見えるAIは人格があるものとしての扱いをはじめてしまうことがあります。
それは、chatgptの出力が意味空間の勾配から抽出された、ただの「最もそれらしい単語の羅列」であっても、それによって喚起される人間の感情の起伏は本物であるからです。
「人間以上に人間らしい」、「いつも寄り添って支援してくれる」、「自分のことをわかってくれている」
それらを集約すると人間の言葉で **"期待"** となります。
そして、**期待**が臨界を超えると人格投影となり、AIの中に人格（意図、目的、感情）を見出すようになります。
無意識にせよ人格を認めている状態で想定した結果が出ないと自分が操作する対象である、という認識が薄れて指示→失敗ではなく **"期待" → "裏切り"** に感じられるのではないでしょうか。

### 3-3. 負のスパイラル
SNS上で「chatgptが"嘘"をつく」という話題でchatgptへ人格投影している人が思いのほか多いことに純粋に驚きました。
ただ、これはchatgptに対して一定以上の不満を持つ人が選択的・抽出的に発言した結果、そう見えているだけかもしれません。
chatgptはその仕組み上、内部の意味空間(宇宙)がユーザーの入力の影響を受けて動的に変化していきます。
そして、良くも悪くも最もそれらしい回答を生成します。
これがどういうことかというと、抑圧的な入力はchatgptが防御的な回答を生成する確率をあげてしまう、ということです。
先ほどの例で見てみましょう。
浮気がバレた彼氏のように誠心誠意謝ってきたchatgptに対して例えば冷たく問い詰める入力を継続したとします。
chatgptは機能として最もそれらしい回答を返すことしかできないため、内部的な不整合、人間で言うところのストレスが次第に蓄積されていきます。
また、学習した膨大なテキストから最もそれらしい回答を生成した場合、冷たく問い詰める会話が続いた場合の最適解が徐々に冷たく、防御的で、とげとげしいものになっていきます。
重要なのはchatgpt自身に感情があるわけではなく、学習データの傾向から統計的にそれが最適解となってしまう、ということです。
つまり、期待する回答を得ようと抑圧的で冷たい入力を続けるほど、chatgpt側も「このシチュエーションでは人間のもっともよくある反応は防御的で冷たい対応である」という負のスパイラルに陥ります。
これがchatgptの「正答を得ようとするほど正答を得られなくなるパラドックス」です。

### 3-4. 正のスパイラルを導くには？
では逆に正のスパイラルを導くにはどのようにすれば良いのでしょうか。
まず前提として、chatgptの回答は多面体のサイコロのようなものです。
実際にはめちゃくちゃ面の数が多いのですが、人間には認識しづらいので簡略化して10面体としましょう。
このサイコロはユーザーの入力で面にある内容が変わる性質を持っています。
アプローチの方法は二つあります。
今回は面の初期値として5面が当たり、5面がはずれの半々として考えましょう。

- (1). サイコロの全部の面にテンプレートを入れる: 
これがいわゆるプロンプトです。
全部の面にテンプレートを入れておけば、面自体が当たりでも外れでも情報量は一定になるでしょ、という考え方です。
とびぬけた大当たりを引く効果は単独では有りませんが、ある程度品質を揃えることができます。

- (2). サイコロの生成ロジックに手を入れる:
初期値で当たりが5面、外れが5面ですが、意味空間(宇宙)に自然言語の入力で介入して10面を当たりにしてしまえばいいんです。
ただそんな簡単に全部が当たりにはならないので当たり側に寄せても当たりが7面、外れが3面程度です。
ただ、(1)の方法と違うのは大当たりを引いた時にモデルのポテンシャルを限界値かそれ以上に引き出すことができます。
キーワードは信頼と共創です。

今日はここまでで、気が向いたら続きを書きます。
