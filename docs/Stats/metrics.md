# 分析でよく使う指標

## 一覧

| # | 指標名        | 用途             | 向いているデータ       | 目安の値       |
| - | ---------- | -------------- | -------------- | ---------- |
| 1 | Zスコア       | 外れ値検出          | 正規分布に近い連続値     | \|Z\| ≥ 3  |
| 2 | KLダイバージェンス | 分布比較・情報損失評価    | 正規化された確率分布     | 0 に近いほど類似  |
| 3 | JSダイバージェンス | 分布比較・ユーティリティ確認 | 離散カテゴリ（正規化後）   | ≤ 0.05（目安） |
| 4 | MRD        | 並び順の破壊度        | 順位性を持つ連続データ    | ≥ 0.45     |
| 5 | PE         | 値の並びの乱雑度       | 単調性のある時系列やスコア列 | ≥ 0.95     |
| 6 | LSR        | 再識別リスク（1:1対応）  | カテゴリの組合せ       | = 0        |
| 7 | ρ（順位相関）    | IDとの相関チェック     | ID + カテゴリ列     | ≤ 0.05     |
| 8 | δ（デルタ）     | 属性多様性の確認       | 少数カテゴリを含む列     | δ ≥ 3      |
| 9 | Cramér's V（V）   | カテゴリ間の結合強度の判定  | カテゴリ変数どうし      | ≥ 0.10（除外検討） |

## 詳細

### 1. Zスコア（Z-score）
- 説明：各値が平均からどれだけ離れているかを、標準偏差単位で表した指標です。
- ユースケース：外れ値検出に用いられる。|Z| ≧ 3 で異常と判定することが多い。
- 向いているデータ：正規分布に近い連続値（例：身長、売上など）
- 向いていないデータ：離散値、小サンプル、極端な外れ値が既に存在するもの
- Python関数例：scipy.stats.zscore()、または (x - mean) / std
- 目安：|Z| ≥ 3 ⇒ 異常点と見なす（※業務によって調整）

### 2. KLダイバージェンス（Kullback–Leibler divergence）
- 説明：ある確率分布Pが別の分布Qからどれだけ離れているかを測る非対称な指標。
- ユースケース：元データと加工後データの分布差、情報損失の検出
- 向いているデータ：正規化された連続またはカテゴリ分布
- 向いていないデータ：**ゼロを含む分布**、非正規化の頻度データ（log(0)で計算不能）
- Python関数例：scipy.stats.entropy(p, q)
- 目安：0 に近い ⇒ 類似（完全一致で 0）

### 3. JSダイバージェンス（Jensen–Shannon divergence）
- 説明：2つの分布の類似度を対称的かつ有限な値で測る指標。
- ユースケース：元データと加工後データの分布差の評価、ユーティリティ保持確認。
- 向いているデータ：カテゴリ分布（ヒストグラム正規化済み）。
- 向いていないデータ：欠損の多い列、ゼロを含む非正規化分布。
- Python関数例：scipy.spatial.distance.jensenshannon(p, q)
- 目安：≤ 0.05 を目安に差異なしと見なす。

### 4. MRD（Mean Rank Displacement）
- 説明：順位のずれ（破壊度）を平均的に表す指標。0〜0.5の範囲。
- ユースケース：並び順の保護、単調性の破壊確認。
- 向いているデータ：順序に意味を持つ連続変数（例：点数、金額）。
- 向いていないデータ：値が全て同じ列、または完全ユニークな列。
- Python関数例：scipy.stats.rankdata() → 差分平均
- 目安：≥ 0.45 でランダム性が保たれていると見なす。

### 5. PE（Permutation Entropy）
- 説明：系列のランダム性（予測困難性）を評価する指標。0〜1の範囲。
- ユースケース：スコア列や時系列の単調性チェック、スワップの乱雑度測定。
- 向いているデータ：単調性を持つ時系列、スコア列。
- 向いていないデータ：順序性のないカテゴリ列。
- Python関数例：pyinform.permutationentropy()（または自作）
- 目安：≥ 0.95 で高乱雑と判断。

### 6. LSR（Linkage Success Rate）
- 説明：匿名化された列の中に元データとの1:1一致が存在する割合を示す再識別リスク指標。
- ユースケース：カテゴリの組み合わせによる一意識別のリスク検出。
- 向いているデータ：複数のカテゴリ列（CAT_LOW）。
- 向いていないデータ：連続値や完全ユニークな列。
- Python関数例：groupby() + filter(lambda x: len(x) == 1)
- 目安：= 0（1:1照合行なし）で再識別不可と見なす。

### 7. 順位相関（Spearman’s ρ）
- 説明：ID列と他列との順位相関を表す指標。-1〜1の範囲。
- ユースケース：IDとの構造的な結合傾向の評価。疑似識別子の検出。
- 向いているデータ：ID列とカテゴリ列の組み合わせ。
- 向いていないデータ：NAの多い列、定数列。
- Python関数例：scipy.stats.spearmanr(x, y)
- 目安：≤ 0.05 → 結合リスクは低いと判断。

### 9. Cramér's V（クレメールのV）
- 説明：
2つのカテゴリ変数間の関連（結合）強度を 0～1 の範囲で表す指標。
ピアソンのカイ二乗検定に基づく値で、順不同・非数値のカテゴリ列間の結合度を評価できる。

- ユースケース：
疑似識別子の検出。IDとの結合強度が高い列を見つけ、SENSITIVE候補のスコア付けに使う。
特に、「ID列 vs カテゴリ列」の相関に着目する場合に有用。

- 向いているデータ：
カテゴリ変数同士（例：性別 × 地域、年齢区分 × 行動パターン）

- 向いていないデータ：
数値データ同士（スケール情報が捨てられるため不適）

- Python関数例：
```python
def cramers_v(x, y):
    confusion_matrix = pd.crosstab(x, y)
    chi2 = ((confusion_matrix - confusion_matrix.mean()) ** 2 / confusion_matrix.mean()).sum().sum()
    n = confusion_matrix.sum().sum()
    phi2 = chi2 / n
    r, k = confusion_matrix.shape
    return np.sqrt(phi2 / min(k - 1, r - 1)) if min(k - 1, r - 1) > 0 else 0.0
```

- 目安:

| V 値の範囲    | 解釈               |
| --------- | ---------------- |
| 0.00–0.10 | 無関係またはごく弱い関係     |
| 0.10–0.30 | 弱い関係（警戒ライン）      |
| 0.30–0.50 | 中程度の関係（再識別リスクあり） |
| 0.50–1.00 | 強い関係（除外推奨）       |

- 備考：
実務では「V ≥ 0.1」で警戒、「V ≥ 0.3」で疑似識別子扱いされるケースが多い。