# データ評価前の準備ガイド 兼 チェックリスト

## 目的
事前準備が不足したまま分析を開始してしまうと手戻りになるケースがある
手戻りを防止するために分析前に実施しておくべき処理をまとめ、チェックリストとする

## チェック項目
主なチェック項目は以下のとおり

|  番号 | チェック項目        | 内容                                      | なぜ必要か                                    | 使用する関数例（Python）                                                |
| :-: | ------------- | --------------------------------------- | ---------------------------------------- | -------------------------------------------------------------- |
|  1  | ファイル読込・パース確認  | ファイル存在確認、エンコーディング・区切り文字・列数などの整合性確認      | パースミスにより列崩れや欠損誤判定が起きやすく、以後の処理全体に影響を与える   | `os.path.exists()`, `pd.read_csv()`, `df.shape`, `df.columns`  |
|  2  | 欠損値（NA）割合の確認  | 各列にどれだけ欠損が含まれているかを確認                    | 欠損が多すぎる列はスコア計算の信頼性が低くなる、補完方針や除外判断の材料とする  | `df.isna().mean()`                                             |
|  3  | ユニーク値と集中度の確認  | 各列のユニーク値の数、割合、上位カテゴリの構成比を確認             | 一意すぎる列は識別リスクが高く、逆に極端に少ない列は情報量が不足する可能性がある | `df.nunique()`, `df.nunique()/len(df)`, `value_counts()`       |
|  4  | データ型の確認と修正    | 数値・カテゴリ・日時など、意図通りのデータ型が割り当てられているかを確認・修正 | 型が誤っていると相関・JS・スコアなどの計算が破綻するリスクがある        | `df.dtypes`, `astype()`, `pd.to_numeric()`, `pd.to_datetime()` |
|  5  | 指標に適さない列の判別   | 全NA列、定数列、完全ユニーク列などを検出し、分析から除外するか検討      | 多くの指標で評価不能となる列をあらかじめ識別し、後工程のトラブルを未然に防ぐ   | `df.nunique()`, `df[col].isna().mean()`, `df[col].is_unique`   |
|  6  | 順序性の確認（手動判断）  | 並びに意味がある列（例：登録日、スコア、ランクなど）を人間の判断で確認     | MRDやPEなど、順序に意味を持つ指標の適用判断に必要となる           | 設定ファイルで明示、または `col_order_flag` を付与など                           |
|  7  | 分布形状の確認       | 各数値列の分布をヒストグラム・密度プロット等で確認               | 分布の偏り・尖度が極端な列に指標を適用すると誤解釈や誤判定のリスクがある     | `df[col].hist()`, `boxplot()`, `plot(kind='density')`          |
|  8  | 外れ値の検出と対応方針検討 | Zスコアなどを使って外れ値を検出し、保持・補正・除外方針を判断         | 外れ値が統計量を歪めると、全体の分析結果やモデルの予測性能に悪影響を及ぼす    | `scipy.stats.zscore()`, `abs() > 3`                            |
|  9  | ID・主キーの一意性確認  | 主キーやID列が本当に一意かを検証                       | 重複があるとJOINや集計にバグを引き起こし、指標精度や再現性に影響する     | `df[id_col].is_unique`, `duplicated()`                         |
|  10 | ドメイン知識との照合    | 値やNAの意味を業務文脈と照らして確認                     | 欠損が実際は「該当なし」など正当な値である可能性があり、誤った前処理を防ぐ    | 関係者ヒアリングや仕様書参照、チェック結果への注釈記入など                                  |

## チェック内容
### 1. ファイル読込とパース確認
- 目的：
対象ファイルが存在し、指定された形式（エンコーディング・区切り記号など）で正しく読み込めていることを確認する
列数や行数を取得して想定通りのデータであるかどうかを把握するとともに列数や列名のズレがないかを早期に検出する

- 見落とした場合のリスク：
エラー発生時に根本原因が分かりづらく、指標や集計結果が壊れる可能性がある
列のズレは欠損や誤ラベルの原因となり、後工程に波及する

| 項目       | 内容                 | なぜ必要か              | Python 例                     |
| -------- | ------------------ | ------------------ | ---------------------------- |
| ファイル存在確認 | パスが正しいか            | FileNotFound を即時検知 | `os.path.exists(path)`       |
| 読込成功     | エンコーディング・区切り文字が適切か | 列崩れ・欠損誤判定を防止       | `pd.read_csv(...)` |
| 行数・列数    | `df.shape` が想定通りか  | サンプル不足・過多を早期把握     | `print(df.shape)`            |

```python
import os
os.path.exists("data/input/sample.csv")  # ファイル存在確認

df = pd.read_csv("data/input/sample.csv", encoding="utf-8")
print(df.shape)  # 行数・列数確認
print(df.columns)  # 列名確認

```

### 2. 欠損値（NA）の確認
- 目的：
各列に欠損がどの程度含まれているかを把握し、除外や補完などの判断材料とする。

- 見落とした場合のリスク：
NAが多すぎる列がそのまま分析に使われるとスコア算出が不安定になる
NAの偏りが指標結果を歪める可能性もある

- 補記
可視化はmissingnoを使う方法もある
検証環境に依存するため導入されているかどうか、導入が可能かどうかは別途確認すること
`missingno.matrix(df)`

```python
na_ratio = df.isna().mean().round(3)
print(na_ratio.sort_values(ascending=False))  # 欠損率が高い順に表示

```

### 3. ユニーク値と集中度の確認
- 目的：
各列のユニーク値数とその割合を確認し、識別性や情報量の偏りの有無を判断する

見落とした場合のリスク：
完全ユニーク列（識別子）や一極集中型の列（偏りが強いカテゴリ）はスコア評価のバイアス要因となり、再識別リスクや過学習を引き起こす可能性がある。
例えば値の一極集中（例：90%が同じ値）は分布指標 δ 等に影響する
ユニーク率=1.0 の列は識別子候補（再識別リスクが高い）

```python
uniq_abs  = df.nunique()                      # 絶対数
uniq_rate = (df.nunique()/len(df)).round(3)   # 割合
top_freq  = df[col].value_counts(normalize=True).head()
```

### 4. データ型の確認と明示的な修正
- 目的：
各列に適切な型（数値・カテゴリ・日付など）が割り当てられているかを確認し、必要に応じて型変換を行う。

- 見落とした場合のリスク：
データ型が誤っていると、相関・分布距離などの指標が正しく計算されない。特にobject型の誤解釈が多く、処理が不安定になる。

```python
df.dtypes
df['price'] = pd.to_numeric(df['price'], errors='coerce')
df['id']    = df['id'].astype('category')
df['date']  = pd.to_datetime(df['date'], format='%Y-%m-%d')
```

### 5. 一部指標に適さない列の見極め
- 目的：
評価に適さない列（例：すべてNA、すべて同じ値、完全ユニークなど）を事前に識別し、分析対象から除外または慎重に扱う

- 見落とした場合のリスク：
無意味な列を含めた指標計算によって、全体のスコアや再識別リスク評価に誤差が生じる可能性がある
トレーサビリティにも影響する

- 補記：
基本的には全NA列、定数列、完全ユニーク列（ID列など）は多くの指標に適さないため、除外候補とする
ただし、比較する場合に別の意味で役立つ場合（例：リファレンス順としてMRDに使うなど）もあるため、一律に除外すると後工程でのトラブル原因になることがある
実務ではチェックの際にフラグを付与して人間が判断できるようにするとトレーサビリティ確保に強い設計(なぜどのような理由で除外したかを後から追跡可能)となる

| フラグ名          | 条件                                  | 指標への影響例            |
| ------------- | ----------------------------------- | ------------------ |
| `is_all_na`   | すべての値が NA                           | 情報なし。すべての指標で評価不能   |
| `is_constant` | 値がすべて同じ                             | 分布・乱雑度の評価に無意味。除外候補 |
| `is_unique`   | ユニーク値の個数 = 行数（=1行1値）                | 識別子傾向が強く、ρやLSRに影響する、再識別リスクが高い  |
| `na_ratio`    | NA 割合（`df[col].isna().mean()`）      | 欠損が多い場合は指標結果の信頼性低下 |
| `dtype`       | データ型（例：object, float64, datetime 等） | 型により適用できる指標が変わる    |


```python
df.nunique() == len(df)  # 完全ユニーク
df.isna().all()          # 全NA列の検出
df.nunique() == 1        # 定数列の検出
```

### 6.  順序性や構造の確認（手動チェック推奨）
- 目的：
列の並びや構造に意味があるか（例：登録順、スコア順など）を人間の視点で評価する
機械判定では誤解されやすいため、明示的に指定する。

- 見落とした場合のリスク：
本来は順序性を持つ列にMRDやPEを適用しないなどの誤判断が生じ、スコアの妥当性を損ねる恐れがある

- 補記： 
これを機械に任せると適切に判定できないことが往々にしてあるため、この工程は人間が行うことが望ましい
どの指標を適用するか、どの指標でどの範囲をカバーするか（組み合わせの問題）を判断するためにも必要
設定ファイルやメタデータで列属性を明示することを推奨する

  - 順序性: 登録日・スコア・ランクなど
  - 構造例: 階層型カテゴリ（大分類-中分類-小分類）、時系列の周期性

### 7. 数値データの分布形状確認

- 目的：
各数値列の値がどのような分布をしているか（例：正規分布、右に偏った分布など）を確認することで、後続の統計的処理やスコア計算の前提を確かめる
特に JS（Jensen-Shannon距離）や PE（Permutation Entropy）など、分布の形状に敏感な指標を扱う場合に重要

- 見落とした場合のリスク：
分布の偏りや尖度が極端な列に指標を適用すると、誤って異常値と判定されたりユーティリティの誤解釈に繋がることがある

```python
df[col].hist()  # ヒストグラムで分布形状を確認
df.boxplot(column=col)  # 外れ値も含めた分布の概要を視覚化
df[col].plot(kind='density')  # 滑らかな密度曲線を見る
```

### 8. 外れ値の検出と対応方針

- 目的：
統計的に極端な値（外れ値）が存在するかどうかを確認し、分析の精度や信頼性を損なう要因を排除または補正する
外れ値は多くの場合、誤入力・例外ケース・真の異常のいずれかであり適切な対処が求められる

- 見落とした場合のリスク：
外れ値が原因で平均や分散などの統計量が歪み、スコア計算やモデリングの結果に大きな影響を与える
異常値を真の傾向と誤認し、不適切な判断を導く恐れがある

```python
from scipy.stats import zscore
df["z"] = zscore(df[col])
outliers = df[df["z"].abs() > 3]  # Zスコアによる外れ値判定
```

### 9. ID／主キーの一意性確認
- 目的：
ユニークIDや主キーとして期待される列に重複が存在しないことを確認する
特にJOINや集計処理を伴う分析において、IDの一意性は処理結果の正当性を支える前提となる

- 見落とした場合のリスク：
ID重複の存在により、意図しない多重マッチや集計ミスが発生する
特に再識別リスクの評価やスコア統合処理などで誤集計の原因となる

```python
assert df["id"].is_unique, "IDに重複があります"
df["id"].duplicated().sum()  # 重複件数を確認
```

### 10. ドメイン知識の反映
- 目的：
欠損値や分布、値の意味に対する機械的な解釈に加えて、実データの背景や業務的文脈に基づく判断を加える
数値やNAに込められた意味を正確に把握することで、分析上の誤解を防ぐ

- 見落とした場合のリスク：
「NA」は欠損値ではなく「該当なし」を意味する場合があるように、値の意味を誤って解釈することで分析の前提が崩れ、誤結論に至る恐れがある
チェックリストの項目単独では判定できないため、最終的な判断は現場・業務知識を持つ担当者とのすり合わせが必須

### 11. 略語・指標早見表
本チェックリストでは、各工程において複数の略語や指標名が登場する
以下は主要な略記とその意味、および典型的な用途の一覧である
必要に応じて各列ごとのスコア計算やリスク評価時の参考とすること

| 略記  | 正式名                             | 用途の一例          |
| --- | ------------------------------- | -------------- |
| δ   | **Delta**（l-diversity 系指標）      | カテゴリ分布の偏り評価    |
| ρ   | **Spearman’s rank correlation** | 順位相関（IDとの結合傾向） |
| JS  | **Jensen-Shannon divergence**   | 分布類似度の比較       |
| MRD | **Mean Rank Displacement**      | 並び順の破壊度評価      |
| PE  | **Permutation Entropy**         | 乱雑さ（非直線性）の評価   |
| LSR | **Linkage Success Rate**        | 再識別リスク（1:1 合致） |
